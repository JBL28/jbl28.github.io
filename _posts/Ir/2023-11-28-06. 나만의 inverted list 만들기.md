---
title:  "(IR텀프로젝트) 나만의 Inverted List 만들기" 
excerpt: "(IR텀프로젝트) 나만의 Inverted List 만들기"

categories:
  - Ir
tags:
  - [IR, 정보검색, ]

toc: true
toc_sticky: true
 
date: 2023-11-28 22:00:00
last_modified_at: 2023-11-28

---

이번 포스트에서는 앞서 준비한 기능들을 하나로 모아 문서를 크롤링하며 inverted list를 생성하는 기능을 만들어봤습니다.<br>
앞서 보았던 코드들을 이어붙인 것 들이니, 이해가 되지 않는다면 이전 포스트들을 참고해주세요.<br>
바로 코드부터 보여드리겠습니다.<br><br>

```python
conn = pymysql.connect(host='localhost', user='root', password='0000', charset='utf8');
cur = conn.cursor();
sql = "CREATE DATABASE IF NOT EXISTS inverted DEFAULT CHARACTER SET UTF8;";
cur.execute(sql);
cur.execute(("USE inverted"));
sql = "CREATE TABLE IF NOT EXISTS MainList (term char(255), PRIMARY KEY (term));"
cur.execute(sql);

SUM = 0;

dr = webdriver.Chrome()  # 크롬 드라이버를 실행하는 명령어를 dr로 지정
dr2 = webdriver.Chrome()    #하위 문서를 열 드라이버
driver = dr.get('https://terms.naver.com/list.naver?cid=60476&categoryId=60476')  # 드라이버를 통해 url의 웹 페이지를 오픈

selector = "#content > div.contents_list_wrap.sub > ul"         #이 코드부터
links = dr.find_elements(By.CSS_SELECTOR, selector)

start = time.time()
crawlCounter = 0;

for i in links:
    contents = i.find_elements(By.CLASS_NAME, "contents_sub.active")
    for j in contents:
        contents_item = j.find_elements(By.TAG_NAME, "ul")
        for a in contents_item:
            sub_item = a.find_element(By.TAG_NAME, "li")
            item = sub_item.find_element(By.TAG_NAME, "a")      #여기까지는 링크가 담긴 html 구조를 찾는 부분
            href = item.get_attribute("href")                   #해당 코드에서 url을 따온다.
            
            driver2 = dr2.get(href)                             #해당 URL의 페이지를 새로운 드라이버에 띄우고
            title = dr2.find_element(By.CLASS_NAME, "headword").text #제목을 따온다
            texts = dr2.find_element(By.CLASS_NAME, "size_ct_v2").text #내용도 따온다
            
            print(title, "문서 크롤링 중..( 문서길이 :", len(texts), ")")#제목, 길이를 이용해 안내 메시지 출력
            SUM += len(texts)                              #평균을 구하기 위해 문서 길이의 합을 구함
            
            texts = texts.replace("\n", " ")
            okt_pos = Okt().pos(texts, norm=True, stem=True)
            okt_filtering = [x for x, y in okt_pos if y in ['Noun', 'Adjective', 'Verb']]
            
            for term in okt_filtering:
                print(term+"을 색인합니다..")
                cur.execute("SELECT EXISTS (SELECT term FROM mainlist WHERE term = '" + term + "' limit 1) AS FLAG")
                boolean = cur.fetchone()
                if (boolean[0] == 0):
                    sql = "CREATE TABLE IF NOT EXISTS `" + term + "` ( Did char(255), URL char(255), Frequency int, PRIMARY KEY (Did));";
                    cur.execute(sql);
                    sql = "INSERT INTO `" + term + "` (Did, URL, Frequency) VALUES ('" + title + "', '" + href + "', 1);"
                    cur.execute(sql);
                    sql = "INSERT INTO mainlist (term) VALUES ('" + term + "');"
                    cur.execute(sql);
                else:
                    cur.execute("SELECT EXISTS (SELECT * FROM `" + term + "` WHERE Did = '" + title + "' limit 1) AS FLAG")
                    boolean = cur.fetchone()
                    if (boolean[0] == 0):
                        sql = "INSERT INTO `" + term + "` (Did, URL, Frequency) VALUES ('" + title + "', '" + href + "', 1);"
                        cur.execute(sql);
                    else:
                        sql = "SELECT Frequency FROM `" + term + "` WHERE Did = '" + title + "';";
                        cur.execute(sql);
                        temp = cur.fetchone()
                        num = 1 + int(temp[0])
                        sql = "UPDATE `" + term + "` SET Frequency = " + str(num) + " WHERE Did = '" + title + "';"
                        cur.execute(sql);
            
            f = open(title+".txt", "w+", encoding = "utf-8")        #제목을 텍스트파일의 제목으로 설정하고,
            f.write(title + "\n\n\n" + texts)                       #크롤링한 제목과 내용을 저장한다.
            f.close()
            crawlCounter = crawlCounter + 1
            
end = time.time()
MEAN = SUM / crawlCounter

sql = "CREATE TABLE IF NOT EXISTS information (num int, averlen int);"
cur.execute(sql);
sql = "INSERT INTO information (num, averlen) VALUES ("+ str(crawlCounter) +", " + str(int(MEAN)) +")"
cur.execute(sql);

conn.commit();
conn.close();

print(f"{end - start:.5f} 초 동안" + str(crawlCounter) + "개의 문서를 크롤링했습니다.")
print("문서 평균 길이 : " + str(int(MEAN)))
```
<br><br>
정말 기네요..ㅋㅋ<br>
이 프로그램이 실행되면, 네이버 악기백과의 문서들이 txt파일로 저장되며, mysql로 구현된 데이터베이스에 inverted list가 만들어집니다.<br>
실행화면으로 보여드리겠습니다.<br><br>

>저장된 파일<br>
>![저장된파일](/assets/images/Ir/06/저장된파일_.png "저장된파일_")

저장된 파일들입니다.<br>
이런 파일들이 끝도 없이 생성되었습니다.(약 300개의 문서를 수집했습니다.)<br><br>

>테이블 목록<br>
>![테이블](/assets/images/Ir/06/테이블_.png "테이블_")

term들의 테이블도 역시 끝도 없이 생성되었습니다.<br>
수많은 테이블 중, 오케스트라 테이블을 한번 살펴보겠습니다.<br><br>

>오케스트라 테이블<br>
>![오케스트라](/assets/images/Ir/06/오케스트라_.png "오케스트라_")

정상적으로 frequency가 기록된 모습입니다!<br>
성공이네요!<br><br>

다음 포스트에서는 웹에서 mysql을 실행하고, 값을 가져오는 기능을 구현해보겠습니다.<br><br>

읽어주셔서 감사합니다! <br>틀린 부분이 있으면 언제든 댓글 달아주세요!
{: .notice--primary} 
